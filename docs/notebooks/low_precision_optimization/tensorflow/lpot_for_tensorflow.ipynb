{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achieve better inference performance by quantizing a pre-trained model from Model Zoo for Intel(R) Architecture with LPOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users will learn how to use Intel(R) Low Precision Optimization Tool ([LPOT](https://github.com/intel/lpot)) to quantize pre-trained model from Model Zoo for Intel(R) Architecture and achieve better inference performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "### Import required python packages and check their version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the Tensorflow is **2.3** or later. LPOT, matplotlib are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version {}\".format(tf.__version__))\n",
    "\n",
    "import lpot\n",
    "print(\"LPOT version {}\".format(lpot.__version__))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pre-trained Model from Model Zoo for Intel(R) Architecture\n",
    "\n",
    "Download pretrained TensorFlow fp32 Resnet50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf resnet50_fp32_pretrained_model.pb\n",
    "!wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/resnet50_fp32_pretrained_model.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la resnet50_fp32_pretrained_model.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the ImageNet dataset\n",
    "\n",
    "The pretrained Resnet50 Models in Model Zoo for Intel(R) Architecture are trained based on [ImageNet](http://www.image-net.org/index). The same training dataset is used to quantize the model by LPOT and then get the accuracy accordingly.\n",
    "\n",
    "Download and the ImageNet dataset using the [instructions](https://github.com/IntelAI/models/blob/master/datasets/imagenet/README.md) here. After running the conversion script you should have a directory with the ImageNet dataset as a TF records format, like:\n",
    "```\n",
    "  tf_records/\n",
    "            train\n",
    "            validation\n",
    "```\n",
    "In this sample, we use the validation dataset for calibration & evaluation with LPOT. \n",
    "\n",
    "We copy the folder **validation** to the local folder as **tf_2012_val**. \n",
    "\n",
    "Check if the folder exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la tf_2012_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize FP32 Resnet50 Model by LPOT\n",
    "The LPOT API will use the stdout to collect the info at runtime. To avoid issues for getting stdout in Jupyter notebook,  we prepare a seperated python script \"**lpot_quantize_model.py**\" to finish the all quantization jobs with LPOT.\n",
    "\n",
    "Please refer to [introduction](https://github.com/intel/lpot/blob/master/docs/introduction.md) for more details.\n",
    "\n",
    "\n",
    "Users need to go through below steps for quantizing a fp32 resnet model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Edit a YAML File\n",
    "\n",
    "#### Create a YAML File\n",
    "\n",
    "We copy [resnet50_v1.yaml](https://github.com/intel/lpot/blob/master/examples/tensorflow/image_recognition/resnet50_v1.yaml) to local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update for Dataset\n",
    "\n",
    "We use the pre-defined **Dataloader** in LPOT. Please set the ImageNet folder to **tf_2012_val** in a YAML file.\n",
    "\n",
    "1.Calibration Dataset\n",
    "\n",
    "Set the calibration dataset folder for ImageNet section:\n",
    "```\n",
    "quantization:\n",
    "  ...\n",
    "  Imagenet:\n",
    "    root: tf_2012_val\n",
    "  ...\n",
    "  \n",
    "```\n",
    "\n",
    "2.Evaluation dataset\n",
    "\n",
    "Set the evaluation dataset folder for accuracy and performance sections:\n",
    "\n",
    "```\n",
    "evaluation: \n",
    "  accuracy:\n",
    "  ...\n",
    "    Imagenet:\n",
    "      root: tf_2012_val\n",
    "  ...    \n",
    "          \n",
    "\n",
    "  performance:\n",
    "  ...\n",
    "    Imagenet:\n",
    "      root: tf_2012_val\n",
    "  ...    \n",
    "          \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat resnet50_v1.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Tuning Function\n",
    "Call Quantization APIs via the auto_tune function, and a frozen quantized model (int8 model) will be generated.\n",
    "\n",
    "Moreover, we define a function to save the model as a PB file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the code in \"**lpot_quantize_model.py**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat lpot_quantize_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the Script to Quantize the Model\n",
    "\n",
    "Execute the \"**lpot_quantize_model.py**\" to show the whole process of quantizing a model.\n",
    "\n",
    "Note, it will take about 0.5-2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python lpot_quantize_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, users will get a quantized model file \"**resnet50_int8_model.pb**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Quantized Model\n",
    "\n",
    "Model Zoo for Intel(R) Architecture provides an inference script [launch_benchmark.py](https://github.com/IntelAI/models/blob/master/benchmarks/launch_benchmark.py) to measure the throughput, latency and accuracy of the FP32 & INT8 model.\n",
    "\n",
    "For accuracy, we use the dataset defined in YAML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare a bash script **local_banchmark.sh** as a wrapper script for **launch_benchmark.py** to benchmarking the model.\n",
    "\n",
    "Three parameters are required:\n",
    "\n",
    "1. Dataset path: It must be the **relative path** of the dataset.\n",
    "\n",
    "2. Model file\n",
    "\n",
    "3. Precision: [fp32 | int8]\n",
    "\n",
    "Three results files will be generated: \n",
    "\n",
    "1. [Precision]_throughput.txt\n",
    "   \n",
    "2. [Precision]_latency.txt\n",
    "    \n",
    "3. [Precision]_accuracy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat local_banchmark.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP32 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run local_banchmark.sh to measure the throughput, latency and accuracy of FP32 model **resnet50_fp32_pretrained_model.pb**.\n",
    "\n",
    "The first argument **tf_2012_val** is the relative path of the dataset. You could change it as yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ./local_banchmark.sh tf_2012_val resnet50_fp32_pretrained_model.pb fp32 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INT8 Model\n",
    "\n",
    "Run local_banchmark.sh to measure the throughput, latency and accuracy of INT8 model **resnet50_int8_model.pb**.\n",
    "\n",
    "It will save the test result in different text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!bash ./local_banchmark.sh tf_2012_val resnet50_int8_model.pb int8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to JSON format\n",
    "\n",
    "We prepare a script **format2json.py** to convert the test result files into the json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python format2json.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the performance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def autolabel(ax, rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%0.5f' % float(height),\n",
    "        ha='center', va='bottom')\n",
    "\n",
    "def draw_bar(x, t, y, subplot, color, x_lab, y_lab, width=0.2):\n",
    "    plt.subplot(subplot)\n",
    "    plt.xticks(x, t)\n",
    "    ax1 = plt.gca()\n",
    "    ax1.set_xlabel(x_lab)\n",
    "    ax1.set_ylabel(y_lab, color=color)\n",
    "    rects1 = ax1.bar(x, y, color=color, width=width)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    autolabel(ax1, rects1)\n",
    "\n",
    "def load_res(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "        return data\n",
    "\n",
    "res_32 = load_res('fp32.json')\n",
    "res_8 = load_res('int8.json')\n",
    "   \n",
    "accuracys = [res_32['accuracy'], res_8['accuracy']]\n",
    "throughputs = [res_32['throughput'], res_8['throughput']]             \n",
    "latencys = [res_32['latency'], res_8['latency']]\n",
    "\n",
    "print('throughputs', throughputs)\n",
    "print('latencys', latencys)\n",
    "print('accuracys', accuracys)\n",
    "\n",
    "accuracys_perc = [accu*100 for accu in accuracys]\n",
    "\n",
    "t = ['FP32', 'INT8']\n",
    "x = [0, 1]\n",
    "plt.figure(figsize=(16,6))\n",
    "draw_bar(x, t, throughputs, 131, 'tab:green', 'Throughput(fps)', '', width=0.4)\n",
    "draw_bar(x, t,  latencys, 132, 'tab:blue', 'Latency(s)', '', width=0.4)\n",
    "draw_bar(x, t,  accuracys_perc, 133, '#28a99d', 'Accuracys(%)', '', width=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance comparison between FP32 and INT8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughputs_times = [1, throughputs[1]/throughputs[0]]\n",
    "latencys_times = [1, latencys[1]/latencys[0]]\n",
    "accuracys_times = [0, accuracys_perc[1] - accuracys_perc[0]]\n",
    "\n",
    "print('throughputs_times', throughputs_times)\n",
    "print('latencys_times', latencys_times)\n",
    "print('accuracys_times', accuracys_times)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "draw_bar(x, t, throughputs_times, 131, 'tab:green', 'Throughput Comparison (big is better)', '', width=0.2)\n",
    "draw_bar(x, t, latencys_times, 132, 'tab:blue', 'Latency Comparison (small is better)', '', width=0.2)\n",
    "draw_bar(x, t, accuracys_times, 133, '#28a99d', 'Accuracys Loss(%)', '', width=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[CODE_SAMPLE_COMPLETED_SUCCESFULLY]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlopt_kernel",
   "language": "python",
   "name": "vlopt_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
