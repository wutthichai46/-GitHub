From 478705ef26374373cc188eb316cfeabb48bfbbc5 Mon Sep 17 00:00:00 2001
From: ltsai1 <louie.tsai@intel.com>
Date: Fri, 21 Jan 2022 17:21:31 -0800
Subject: [PATCH] transformer_mlperf train bfloat16

---
 .../training/bfloat16/transformer/transformer_main.py    | 9 ++++++++-
 1 file changed, 8 insertions(+), 1 deletion(-)

diff --git a/models/language_translation/tensorflow/transformer_mlperf/training/bfloat16/transformer/transformer_main.py b/models/language_translation/tensorflow/transformer_mlperf/training/bfloat16/transformer/transformer_main.py
index cf903ad33..d5748e575 100644
--- a/models/language_translation/tensorflow/transformer_mlperf/training/bfloat16/transformer/transformer_main.py
+++ b/models/language_translation/tensorflow/transformer_mlperf/training/bfloat16/transformer/transformer_main.py
@@ -44,6 +44,9 @@ from utils import dataset
 from utils import metrics
 from utils import tokenizer
 
+sys.path.append(os.environ['ProfileUtilsRoot'])
+from profile_utils import ConfigFile, tfProfileHook
+
 tf.compat.v1.disable_eager_execution()
 #Horovod support
 global is_mpi 
@@ -322,6 +325,10 @@ def train_schedule(
   if FLAGS.save_profile == "Yes":
     profile_hooks = [tf.compat.v1.train.ProfilerHook(save_steps=1, output_dir=FLAGS.profile_dir)] # the json file 
   #profile file will be saved in in profile_dir
+  config = ConfigFile(confpath=os.environ['ProfileUtilsRoot']+"/topo.ini")
+  config.read_config("transformer_mlperf train bfloat16")
+  profile_hook = [tfProfileHook(save_steps=1, json_fname=config.json_fname)]
+
   #Creating hooks for printing Examples per Second, used with estimator.train
   training_batch_size = estimator.params.batch_size
   if FLAGS.batch_size is not -1:
@@ -336,7 +343,7 @@ def train_schedule(
   if FLAGS.save_profile == "Yes":
     hooks = profile_hooks
   else:
-    hooks = train_hooks
+    hooks = train_hooks + profile_hook
   
   for i in xrange(train_eval_iterations):
     print("Starting iteration", i + 1)
-- 
2.32.0

