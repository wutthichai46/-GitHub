apiVersion: v1
kind: Pod
metadata:
  name: rfcn-fp32-inference # {"$openapi":"MODEL_NAME"}
spec:
  serviceAccountName: rfcn-fp32-inference # {"$openapi":"MODEL_NAME"}
  securityContext:
    runAsUser: 0 # {"$openapi":"USER_ID"}
    runAsGroup: 0 # {"$openapi":"GROUP_ID"}
    fsGroup: 0 # {"$openapi":"FS_ID"}
  containers:
  - name: serving
    image: docker.io/intel/object-detection:tf-2.3.0-imz-2.2.0-rfcn-fp32-inference # {"$openapi":"IMAGE"}
    workingDir: /workspace/rfcn-fp32-inference # {"$openapi":"MODEL_DIR"}
    command: # {"$openapi":"COMMAND"}
    - /workspace/rfcn-fp32-inference/quickstart/fp32_inference.sh # {"$openapi":"COMMAND"}
    envFrom:
    - configMapRef:
        name: rfcn-fp32-inference # {"$openapi":"MODEL_NAME"}
    volumeMounts:
    - name: datasets
      mountPath: /datasets # {"$openapi":"DATASET_DIR"}
      readOnly: true
    - name: nfs-path
      mountPath: /nfs # {"$openapi":"NFS_PATH"}
    - name: mlops-scripts
      mountPath: /workspace/rfcn-fp32-inference/quickstart/fp32_inference.sh # {"$openapi":"COMMAND"}
      subPath: fp32_inference.sh # {"$openapi":"MODEL_SCRIPT"}
  volumes:
  - name: datasets
    hostPath:
      path: /datasets # {"$openapi":"DATASET_DIR"}
  - name: nfs-path
    nfs:
      server: 0.0.0.0 # {"$openapi":"NFS_SERVER"}
      path: /nfs # {"$openapi":"NFS_PATH"}
  - name: mlops-scripts
    configMap:
      name: rfcn-fp32-inference # {"$openapi":"MODEL_NAME"}
      defaultMode: 0770
      items:
      - key: fp32_inference.sh # {"$openapi":"MODEL_SCRIPT"}
        path: fp32_inference.sh # {"$openapi":"MODEL_SCRIPT"}
  restartPolicy: OnFailure
