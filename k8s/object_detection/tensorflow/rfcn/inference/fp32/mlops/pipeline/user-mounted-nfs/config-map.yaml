kind: ConfigMap
apiVersion: v1
metadata:
  name: rfcn-fp32-inference # {"$openapi":"MODEL_NAME"}
data:
  ANNOTATIONS_DIR: /datasets/annotations # {"$openapi":"ANNOTATIONS_DIR"}
  DATASET_DIR: /datasets # {"$openapi":"DATASET_DIR"}
  FS_ID: "0" # {"$openapi":"FS_ID_VALUE"}
  GROUP_ID: "0" # {"$openapi":"GROUP_ID_VALUE"}
  GROUP_NAME: root # {"$openapi":"GROUP_NAME"}
  OUTPUT_DIR: /nfs/root/rfcn-fp32-inference/output # {"$openapi":"OUTPUT_PATH"}
  USER_ID: "0" # {"$openapi":"USER_ID_VALUE"}
  USER_NAME: root # {"$openapi":"USER_NAME"}
  VAL_IMAGE_DIR: /datasets/val2017 # {"$openapi":"VAL_IMAGE_DIR"}
  preprocess_coco_val.sh: |
    #!/usr/bin/env bash
    #
    # Copyright (c) 2020 Intel Corporation
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #    http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    #

    # This script preprocesses the validation images for the COCO Dataset to create
    # TF records files. The raw validation images and annotations must be downloaded
    # prior to running this script (https://cocodataset.org/#download).
    #
    # The following vars need to be set:
    #   VAL_IMAGE_DIR: Points to the raw validation images (extracted from val2017.zip)
    #   ANNOTATIONS_DIR: Points to the annotations (extracted from annotations_trainval2017.zip)
    #   OUTPUT_DIR: Path where the TF records file will be written
    #
    # This is intended to be used with the create_coco_tf_record.py script from the
    # TensorFlow Model Garden, commit 1efe98bb8e8d98bbffc703a90d88df15fc2ce906.
    #
    # NOTE: This pre-processes the validation images only

    # If the DATASET_DIR is set, then ensure it exists and set paths for the images and annotations
    if [[ ! -z "${DATASET_DIR}" ]]; then
      if [[ ! -d "${DATASET_DIR}" ]]; then
        echo "ERROR: The specified DATASET_DIR ($DATASET_DIR) does not exist."
        exit 1
      fi

      VAL_IMAGE_DIR=${DATASET_DIR}/val2017
      ANNOTATIONS_DIR=${DATASET_DIR}/annotations
    fi

    # Verify that the a directory exists for the raw validation images
    if [[ ! -d "${VAL_IMAGE_DIR}" ]]; then
      echo "ERROR: The VAL_IMAGE_DIR (${VAL_IMAGE_DIR}) does not exist. This var needs to point to the raw coco validation images."
      exit 1
    fi

    # Verify that the a directory exists for the annotations
    if [[ ! -d "${ANNOTATIONS_DIR}" ]]; then
      echo "ERROR: The ANNOTATIONS_DIR (${ANNOTATIONS_DIR}) does not exist. This var needs to point to the coco annotations directory."
      exit 1
    fi

    # Verify that we have the path to the tensorflow/models code
    if [[ ! -d "${TF_MODELS_DIR}" ]]; then
      echo "ERROR: The TF_MODELS_DIR var needs to be defined to point to a clone of the tensorflow/models git repo"
      exit 1
    fi

    # Create the output directory in case it doesn't already exist
    mkdir -p ${OUTPUT_DIR}

    # Checkout the specified branch for the tensorflow/models code
    if [[ ! -z "${TF_MODELS_BRANCH}" ]]; then
      cd ${TF_MODELS_DIR}
      git checkout ${TF_MODELS_BRANCH}
    fi

    # Set the PYTHONPATH
    cd ${TF_MODELS_DIR}/research
    export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim

    # Create empty dir and json for train/test image preprocessing, so that we don't require
    # the user to also download train/test images when all that's needed is validation images.
    EMPTY_DIR=${OUTPUT_DIR}/empty_dir
    EMPTY_ANNOTATIONS=${OUTPUT_DIR}/empty.json
    mkdir -p ${EMPTY_DIR}
    echo "{ \"images\": {}, \"categories\": {}}" > ${EMPTY_ANNOTATIONS}

    cd ${TF_MODELS_DIR}/research/object_detection/dataset_tools
    python create_coco_tf_record.py --logtostderr \
          --train_image_dir="${EMPTY_DIR}" \
          --val_image_dir="${VAL_IMAGE_DIR}" \
          --test_image_dir="${EMPTY_DIR}" \
          --train_annotations_file="${EMPTY_ANNOTATIONS}" \
          --val_annotations_file="${ANNOTATIONS_DIR}/instances_val2017.json" \
          --testdev_annotations_file="${EMPTY_ANNOTATIONS}" \
          --output_dir="${OUTPUT_DIR}"

    # remove dummy directory and annotations file
    rm -rf ${EMPTY_DIR}
    rm -rf ${EMPTY_ANNOTATIONS}

    # since we only grab the validation dataset, the TF records files for train
    # and test images are size 0. Delete those to prevent confusion.
    rm -f ${OUTPUT_DIR}/coco_testdev.record
    rm -f ${OUTPUT_DIR}/coco_train.record

    echo "TF records in the output directory:"
    ls -l ${OUTPUT_DIR}
  fp32_accuracy.sh: |
    #!/usr/bin/env bash
    #
    # Copyright (c) 2020 Intel Corporation
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #    http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    #

    if [ -z "${OUTPUT_DIR}" ]; then
      echo "The required environment variable OUTPUT_DIR has not been set"
      exit 1
    fi

    # Create the output directory in case it doesn't already exist
    mkdir -p ${OUTPUT_DIR}

    if [ -z "${DATASET_DIR}" ]; then
      echo "The required environment variable DATASET_DIR has not been set"
      exit 1
    fi

    if [ -z "${TF_MODELS_DIR}" ]; then
      echo "The required environment variable MODELS_DIR has not been set"
      exit 1
    fi

    # Untar pretrained model files
    pretrained_model_dir="${OUTPUT_DIR}/pretrained_model/rfcn_resnet101_coco_2018_01_28"
    if [ ! -d "${pretrained_model_dir}" ]; then
      mkdir -p ${OUTPUT_DIR}/pretrained_model
      tar -C ${OUTPUT_DIR}/pretrained_model/ -xvf pretrained_model/rfcn_fp32_model.tar.gz
      chmod -R u+w ${OUTPUT_DIR}/pretrained_model/
    fi
    FROZEN_GRAPH="${pretrained_model_dir}/frozen_inference_graph.pb"

    source "$(dirname $0)/common/utils.sh"
    _command python benchmarks/launch_benchmark.py \
        --model-name rfcn \
        --mode inference \
        --precision fp32 \
        --framework tensorflow \
        --model-source-dir ${TF_MODELS_DIR} \
        --data-location ${DATASET_DIR} \
        --in-graph ${FROZEN_GRAPH} \
        --batch-size 1 \
        --accuracy-only \
        --output-dir ${OUTPUT_DIR} \
        $@ \
        -- split="${OUTPUT_DIR}/accuracy_message"
