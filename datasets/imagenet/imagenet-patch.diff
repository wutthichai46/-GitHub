diff --git a/tools/datasets/imagenet_to_gcs.py b/tools/datasets/imagenet_to_gcs.py
index 86becfe..4c05f89 100644
--- a/tools/datasets/imagenet_to_gcs.py
+++ b/tools/datasets/imagenet_to_gcs.py
@@ -52,6 +52,8 @@ from absl import flags
 from absl import logging
 
 import tensorflow.compat.v1 as tf
+tf.disable_eager_execution()
+
 
 from google.cloud import storage
 
@@ -168,9 +170,9 @@ def _convert_to_example(filename, image_buffer, label, synset, height, width):
   Returns:
     Example proto
   """
-  colorspace = 'RGB'
+  colorspace = b'RGB'
   channels = 3
-  image_format = 'JPEG'
+  image_format = b'JPEG'
 
   example = tf.train.Example(features=tf.train.Features(feature={
       'image/height': _int64_feature(height),
@@ -178,9 +180,9 @@ def _convert_to_example(filename, image_buffer, label, synset, height, width):
       'image/colorspace': _bytes_feature(colorspace),
       'image/channels': _int64_feature(channels),
       'image/class/label': _int64_feature(label),
-      'image/class/synset': _bytes_feature(synset),
+      'image/class/synset': _bytes_feature(synset.encode()),
       'image/format': _bytes_feature(image_format),
-      'image/filename': _bytes_feature(os.path.basename(filename)),
+      'image/filename': _bytes_feature(os.path.basename(filename.encode())),
       'image/encoded': _bytes_feature(image_buffer)}))
   return example
 
@@ -273,7 +275,7 @@ def _process_image(filename, coder):
     width: integer, image width in pixels.
   """
   # Read the image file.
-  with tf.gfile.FastGFile(filename, 'r') as f:
+  with tf.gfile.FastGFile(filename, 'rb') as f:
     image_data = f.read()
 
   # Clean the dirty data.
@@ -344,8 +346,9 @@ def _process_dataset(filenames, synsets, labels, output_directory, prefix,
   for shard in range(num_shards):
     chunk_files = filenames[shard * chunksize : (shard + 1) * chunksize]
     chunk_synsets = synsets[shard * chunksize : (shard + 1) * chunksize]
+    single_filename = "{0}-{1:05d}-of-{2:05d}".format(prefix,shard,num_shards)
     output_file = os.path.join(
-        output_directory, '%s-%.5d-of-%.5d', (prefix, shard, num_shards))
+        output_directory, single_filename)
     _process_image_files_batch(coder, output_file, chunk_files,
                                chunk_synsets, labels)
     logging.info('Finished writing file: %s', output_file)
@@ -360,7 +363,7 @@ def convert_to_tf_records(raw_data_dir):
   # across the batches.
   random.seed(0)
   def make_shuffle_idx(n):
-    order = range(n)
+    order = list(range(n))
     random.shuffle(order)
     return order

