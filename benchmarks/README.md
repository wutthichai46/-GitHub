# Model Zoo Scripts

Training and inference scripts with Intel-optimized MKL

## Prerequisites

The model scripts can be run on Linux and require the following
dependencies to be installed:
* [Docker](https://docs.docker.com/install/)
* [Python](https://www.python.org/downloads/) 3.5 or later
* [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
* `wget` for downloading pre-trained models

## TensorFlow Use Cases

| Use Case                | Framework    | Model              | Mode      | oneContainer Portal | Run from the Model Zoo repository |
| ----------------------- | ------------ | ------------------ | --------- | ------------------- | --------------------------------- |
| Image Recognition       | TensorFlow   | [DenseNet169](https://arxiv.org/pdf/1608.06993.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/densenet169-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/densenet169-fp32-inference-tensorflow-model.html) | [FP32](image_recognition/tensorflow/densenet169/README.md#fp32-inference-instructions) |
| Image Recognition       | TensorFlow   | [Inception V3](https://arxiv.org/pdf/1512.00567.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv3-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv3-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv3-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv3-fp32-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/inceptionv3/README.md#int8-inference-instructions) [FP32](image_recognition/tensorflow/inceptionv3/README.md#fp32-inference-instructions) |
| Image Recognition       | TensorFlow   | [Inception V4](https://arxiv.org/pdf/1602.07261.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv4-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv4-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv4-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv4-fp32-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/inceptionv4/README.md#int8-inference-instructions) [FP32](image_recognition/tensorflow/inceptionv4/README.md#fp32-inference-instructions) |
| Image Recognition       | TensorFlow   | [MobileNet V1*](https://arxiv.org/pdf/1704.04861.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/mobilenetv1-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/mobilenetv1-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/mobilenetv1-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/mobilenetv1-fp32-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/mobilenet_v1/README.md#int8-inference-instructions) [FP32](image_recognition/tensorflow/mobilenet_v1/README.md#fp32-inference-instructions) [BFloat16**](image_recognition/tensorflow/mobilenet_v1/README.md#bfloat16-inference-instructions) |
| Image Recognition       | TensorFlow   | [ResNet 101](https://arxiv.org/pdf/1512.03385.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet101-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet101-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet101-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet101-fp32-inference-tensorflow-model.html) | [Int8](image_recognition/tensorflow/resnet101/README.md#int8-inference-instructions) [FP32](image_recognition/tensorflow/resnet101/README.md#fp32-inference-instructions) |
| Image Recognition       | TensorFlow   | [ResNet 50](https://arxiv.org/pdf/1512.03385.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-fp32-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/resnet50/README.md#int8-inference-instructions) [FP32](image_recognition/tensorflow/resnet50/README.md#fp32-inference-instructions) |
| Image Recognition       | TensorFlow   | [ResNet 50v1.5](https://github.com/tensorflow/models/tree/master/official/resnet) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-fp32-inference-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-bfloat16-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-fp32-inference-model-package.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-bfloat16-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/resnet50v1_5/README.md#int8-inference-instructions) [FP32](image_recognition/tensorflow/resnet50v1_5/README.md#fp32-inference-instructions) [BFloat16**](image_recognition/tensorflow/resnet50v1_5/README.md#bfloat16-inference-instructions) |
| Image Recognition       | TensorFlow   | [ResNet 50v1.5](https://github.com/tensorflow/models/tree/master/official/resnet) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-fp32-training-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-bfloat16-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-fp32-training-tensorflow-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-bfloat16-training-tensorflow-model.html)  | [FP32](image_recognition/tensorflow/resnet50v1_5/README.md#fp32-training-instructions) [BFloat16**](image_recognition/tensorflow/resnet50v1_5/README.md#bfloat16-training-instructions) |
| Image Segmentation      | TensorFlow   | [UNet](https://arxiv.org/pdf/1606.06650.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/unet-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/unet-fp32-inference-tensorflow-model.html)  | [FP32](image_segmentation/tensorflow/unet/README.md#fp32-inference-instructions) |
| Image Segmentation      | TensorFlow   | [MaskRCNN](https://arxiv.org/abs/1703.06870) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/mask-rcnn-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/mask-rcnn-fp32-inference-tensorflow-model.html)  | [FP32](image_segmentation/tensorflow/maskrcnn/README.md#fp32-training-instructions) |
| Language Modeling       | TensorFlow   | [BERT](https://arxiv.org/pdf/1810.04805.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-fp32-inference-tensorflow-model.html)  | [FP32](language_modeling/tensorflow/bert_large/README.md#fp32-inference-instructions) [BFloat16**](language_modeling/tensorflow/bert_large/README.md#bfloat16-inference-instructions) |
| Language Modeling       | TensorFlow   | [BERT](https://arxiv.org/pdf/1810.04805.pdf) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-fp32-training-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-bfloat16-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-fp32-training-tensorflow-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-bfloat16-training-tensorflow-model.html)  | [FP32](language_modeling/tensorflow/bert_large/README.md#fp32-training-instructions) [BFloat16**](language_modeling/tensorflow/bert_large/README.md#bfloat16-training-instructions) |
| Language Translation    | TensorFlow   | [BERT](https://arxiv.org/pdf/1810.04805.pdf) | Inference |  | [FP32](language_translation/tensorflow/bert/README.md#fp32-inference-instructions) |
| Language Translation    | TensorFlow   | [GNMT*](https://arxiv.org/pdf/1609.08144.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/gnmt-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/gnmt-fp32-inference-tensorflow-model.html) | [FP32](language_translation/tensorflow/mlperf_gnmt/README.md#fp32-inference-instructions) |
| Language Translation    | TensorFlow   | [Transformer_LT_Official](https://arxiv.org/pdf/1706.03762.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-official-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-official-fp32-inference-tensorflow-model.html)  | [FP32](language_translation/tensorflow/transformer_lt_official/README.md#fp32-inference-instructions) |
| Language Translation    | TensorFlow   | [Transformer_LT_mlperf](https://arxiv.org/pdf/1706.03762.pdf) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-mlperf-fp32-training-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-mlperf-bfloat16-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-mlperf-fp32-training-tensorflow-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-mlperf-bfloat16-training-tensorflow-model.html) | [FP32](language_translation/tensorflow/transformer_mlperf/README.md#fp32-training-instructions) [BFloat16**](language_translation/tensorflow/transformer_mlperf/README.md#bfloat16-training-instructions) |
| Object Detection        | TensorFlow   | [Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/faster-rcnn-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/faster-rcnn-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/faster-rcnn-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/faster-rcnn-fp32-inference-tensorflow-model.html)  | [Int8](object_detection/tensorflow/faster_rcnn/README.md#int8-inference-instructions) [FP32](object_detection/tensorflow/faster_rcnn/README.md#fp32-inference-instructions) |
| Object Detection        | TensorFlow   | [R-FCN](https://arxiv.org/pdf/1605.06409.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-fp32-inference-tensorflow-model.html)  | [Int8](object_detection/tensorflow/rfcn/README.md#int8-inference-instructions) [FP32](object_detection/tensorflow/rfcn/README.md#fp32-inference-instructions) |
| Object Detection        | TensorFlow   | [SSD-MobileNet*](https://arxiv.org/pdf/1704.04861.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-mobilenet-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-mobilenet-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-mobilenet-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-mobilenet-fp32-inference-tensorflow-model.html)  | [Int8](object_detection/tensorflow/ssd-mobilenet/README.md#int8-inference-instructions) [FP32](object_detection/tensorflow/ssd-mobilenet/README.md#fp32-inference-instructions) [BFloat16**](object_detection/tensorflow/ssd-mobilenet/README.md#bfloat16-inference-instructions) |
| Object Detection        | TensorFlow   | [SSD-ResNet34*](https://arxiv.org/pdf/1512.02325.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-inference-tensorflow-model.html)  | [Int8](object_detection/tensorflow/ssd-resnet34/README.md#int8-inference-instructions) [FP32](object_detection/tensorflow/ssd-resnet34/README.md#fp32-inference-instructions) |
| Object Detection        | TensorFlow   | [SSD-ResNet34](https://arxiv.org/pdf/1512.02325.pdf) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-training-tensorflow-model.html)  | [FP32](object_detection/tensorflow/ssd-resnet34/README.md#fp32-training-instructions) [BFloat16**](object_detection/tensorflow/ssd-resnet34/README.md#bf16-training-instructions) |
| Recommendation          | TensorFlow   | [NCF](https://arxiv.org/pdf/1708.05031.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ncf-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ncf-fp32-inference-tensorflow-model.html)  | [FP32](recommendation/tensorflow/ncf/README.md#fp32-inference-instructions) |
| Recommendation          | TensorFlow   | [Wide & Deep Large Dataset](https://arxiv.org/pdf/1606.07792.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-fp32-inference-tensorflow-model.html)  | [Int8](recommendation/tensorflow/wide_deep_large_ds/README.md#int8-inference-instructions) [FP32](recommendation/tensorflow/wide_deep_large_ds/README.md#fp32-inference-instructions) |
| Recommendation          | TensorFlow   | [Wide & Deep Large Dataset](https://arxiv.org/pdf/1606.07792.pdf) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-fp32-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-fp32-training-tensorflow-model.html)  | [FP32](recommendation/tensorflow/wide_deep_large_ds/README.md#fp32-training-instructions) |
| Recommendation          | TensorFlow   | [Wide & Deep](https://arxiv.org/pdf/1606.07792.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-fp32-inference-tensorflow-model.html)  | [FP32](recommendation/tensorflow/wide_deep/README.md#fp32-inference-instructions) |
| Reinforcement           | TensorFlow   | [MiniGo](https://arxiv.org/abs/1712.01815.pdf) | Training |  | [FP32](reinforcement/tensorflow/minigo/README.md#fp32-training-instructions) |
| Text-to-Speech          | TensorFlow   | [WaveNet](https://arxiv.org/pdf/1609.03499.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wavenet-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wavenet-fp32-inference-tensorflow-model.html)  | [FP32](text_to_speech/tensorflow/wavenet/README.md#fp32-inference-instructions) |

## TensorFlow Serving Use Cases

| Use Case               | Framework     | Model               | Mode      | Run from the Model Zoo repository    |
| -----------------------| --------------| ------------------- | --------- |------------------------------|
| Image Recognition      | TensorFlow Serving | [Inception V3](https://arxiv.org/pdf/1512.00567.pdf)        | Inference | [FP32](image_recognition/tensorflow_serving/inceptionv3/README.md#fp32-inference-instructions) |
| Image Recognition      | TensorFlow Serving | [ResNet 50v1.5](https://github.com/tensorflow/models/tree/master/official/resnet) | Inference | [FP32](image_recognition/tensorflow_serving/resnet50v1_5/README.md#fp32-inference-instructions) |
| Language Translation   | TensorFlow Serving | [Transformer_LT_Official](https://arxiv.org/pdf/1706.03762.pdf) | Inference | [FP32](language_translation/tensorflow_serving/transformer_lt_official/README.md#fp32-inference-instructions) |
| Object Detection       | TensorFlow Serving | [SSD-MobileNet](https://arxiv.org/pdf/1704.04861.pdf)       | Inference | [FP32](object_detection/tensorflow_serving/ssd-mobilenet/README.md#fp32-inference-instructions) |

## PyTorch Use Cases

| Use Case                | Framework    | Model              | Mode      | oneContainer Portal | Run from the Model Zoo repository |
| ----------------------- | ------------ | ------------------ | --------- | ------------------- | --------------------------------- |
| Image Recognition       | PyTorch      | [ResNet 50](https://arxiv.org/pdf/1512.03385.pdf)   | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-fp32-inference-pytorch-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-bfloat16-inference-pytorch-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-fp32-inference-pytorch-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-bfloat16-inference-pytorch-model.html)  | [FP32](/quickstart/image_recognition/pytorch/resnet50/inference/fp32/README.md) [BFloat16**](/quickstart/image_recognition/pytorch/resnet50/inference/bf16/README.md) |
| Recommendation          | PyTorch      | [DLRM](https://arxiv.org/pdf/1906.00091.pdf)        | Training  |  | [BFloat16**](../models/recommendation/pytorch/dlrm/training/bf16/README.md#dlrm-mlperf-bf16-training-v07-intel-submission) |

*Means the model belongs to [MLPerf](https://mlperf.org/) models and will be supported long-term.

**Means the BFloat16 data type support is experimental.
