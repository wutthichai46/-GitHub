# Model Zoo Scripts

Training and inference scripts with TensorFlow optimizations that use the
Intel® oneAPI Deep Neural Network Library (Intel® oneDNN) and
Intel® Extension for PyTorch.

## Prerequisites

The model documentation in the tables below have information on the
prerequisites to run each model. The model scripts run on Linux. Select
models are also able to run using bare metal on Windows. For more information
and a list of models that are supported on Windows, see the
[documentation here](/docs/general/tensorflow/LaunchBenchmark.md#running-the-launch-script-on-bare-metal).

The [oneContainer Portal](http://software.intel.com/containers) column has
links for using workload containers and model packages for each model precision.
These containers are built based on images with Intel optimizations for
[TensorFlow](https://hub.docker.com/r/intel/intel-optimized-tensorflow)
or [PyTorch](https://hub.docker.com/r/intel/intel-optimized-pytorch) and
contain all the dependencies, scripts, and pretrained models needed to run
the workload. The model packages have scripts and pretrained model files
used for running on bare metal.

For information on running more advanced use cases using the workload containers see the:
[advanced options documentation](/quickstart/common/tensorflow/ModelPackagesAdvancedOptions.md).

## TensorFlow Use Cases

| Use Case                | Model              | Mode      | oneContainer Portal | Model Documentation |
| ------------------------| ------------------ | --------- | ------------------- | ------------------- |
| Image Recognition       | [DenseNet169](https://arxiv.org/pdf/1608.06993.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/densenet169-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/densenet169-fp32-inference-tensorflow-model.html) | [FP32](image_recognition/tensorflow/densenet169/inference/fp32/README.md) |
| Image Recognition       | [Inception V3](https://arxiv.org/pdf/1512.00567.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv3-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv3-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv3-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv3-fp32-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/inceptionv3/inference/int8/README.md) [FP32](image_recognition/tensorflow/inceptionv3/inference/fp32/README.md) |
| Image Recognition       | [Inception V4](https://arxiv.org/pdf/1602.07261.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv4-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv4-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv4-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/inceptionv4-fp32-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/inceptionv4/inference/int8/README.md) [FP32](image_recognition/tensorflow/inceptionv4/inference/fp32/README.md) |
| Image Recognition       | [MobileNet V1*](https://arxiv.org/pdf/1704.04861.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/mobilenetv1-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/mobilenetv1-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/mobilenetv1-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/mobilenetv1-fp32-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/mobilenet_v1/inference/int8/README.md) [FP32](image_recognition/tensorflow/mobilenet_v1/inference/fp32/README.md) [BFloat16**](image_recognition/tensorflow/mobilenet_v1/README.md#bfloat16-inference-instructions) |
| Image Recognition       | [ResNet 101](https://arxiv.org/pdf/1512.03385.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet101-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet101-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet101-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet101-fp32-inference-tensorflow-model.html) | [Int8](image_recognition/tensorflow/resnet101/inference/int8/README.md) [FP32](image_recognition/tensorflow/resnet101/inference/fp32/README.md) |
| Image Recognition       | [ResNet 50](https://arxiv.org/pdf/1512.03385.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-fp32-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/resnet50/inference/int8/README.md) [FP32](image_recognition/tensorflow/resnet50/inference/fp32/README.md) |
| Image Recognition       | [ResNet 50v1.5](https://github.com/tensorflow/models/tree/master/official/resnet) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-fp32-inference-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-bfloat16-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-fp32-inference-tensorflow-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-bfloat16-inference-tensorflow-model.html)  | [Int8](image_recognition/tensorflow/resnet50v1_5/inference/int8/README.md) [FP32](image_recognition/tensorflow/resnet50v1_5/inference/fp32/README.md) [BFloat16**](image_recognition/tensorflow/resnet50v1_5/inference/bfloat16/README.md) |
| Image Recognition       | [ResNet 50v1.5](https://github.com/tensorflow/models/tree/master/official/resnet) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-fp32-training-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-bfloat16-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-fp32-training-tensorflow-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50v1-5-bfloat16-training-tensorflow-model.html)  | [FP32](image_recognition/tensorflow/resnet50v1_5/training/fp32/README.md) [BFloat16**](image_recognition/tensorflow/resnet50v1_5/training/bfloat16/README.md) |
| Image Segmentation      | [3D U-Net](https://arxiv.org/pdf/1606.06650.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/3d-unet-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/3d-unet-fp32-inference-tensorflow-model.html) | [FP32](image_segmentation/tensorflow/3d_unet/inference/fp32/README.md) |
| Image Segmentation      | [3D U-Net MLPerf](https://arxiv.org/pdf/1606.06650.pdf) | Inference |  | [FP32](image_segmentation/tensorflow/3d_unet_mlperf/README.md) [BFloat16**](image_segmentation/tensorflow/3d_unet_mlperf/README.md#bfloat16-inference-instructions) [Int8](image_segmentation/tensorflow/3d_unet_mlperf/README.md#int8-inference-instructions)|
| Image Segmentation      | [MaskRCNN](https://arxiv.org/abs/1703.06870) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/mask-rcnn-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/mask-rcnn-fp32-inference-tensorflow-model.html)  | [FP32](image_segmentation/tensorflow/maskrcnn/inference/fp32/README.md) |
| Image Segmentation      | [UNet](https://arxiv.org/pdf/1606.06650.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/unet-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/unet-fp32-inference-tensorflow-model.html)  | [FP32](image_segmentation/tensorflow/unet/inference/fp32/README.md) |
| Language Modeling       | [BERT](https://arxiv.org/pdf/1810.04805.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-fp32-inference-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-bfloat16-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-fp32-inference-tensorflow-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-bfloat16-inference-tensorflow-model.html) | [FP32](language_modeling/tensorflow/bert_large/inference/fp32/README.md) [BFloat16**](language_modeling/tensorflow/bert_large/inference/bfloat16/README.md) |
| Language Modeling       | [BERT](https://arxiv.org/pdf/1810.04805.pdf) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-fp32-training-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-bfloat16-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-fp32-training-tensorflow-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/bert-large-bfloat16-training-tensorflow-model.html)  | [FP32](language_modeling/tensorflow/bert_large/training/fp32/README.md) [BFloat16**](language_modeling/tensorflow/bert_large/training/bfloat16/README.md) |
| Language Translation    | [BERT](https://arxiv.org/pdf/1810.04805.pdf) | Inference |  | [FP32](language_translation/tensorflow/bert/README.md#fp32-inference-instructions) |
| Language Translation    | [GNMT*](https://arxiv.org/pdf/1609.08144.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/gnmt-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/gnmt-fp32-inference-tensorflow-model.html) | [FP32](language_translation/tensorflow/mlperf_gnmt/inference/fp32/README.md) |
| Language Translation    | [Transformer_LT_mlperf](https://arxiv.org/pdf/1706.03762.pdf) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-mlperf-fp32-training-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-mlperf-bfloat16-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-mlperf-fp32-training-tensorflow-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-mlperf-bfloat16-training-tensorflow-model.html) | [FP32](language_translation/tensorflow/transformer_mlperf/training/fp32/README.md) [BFloat16**](language_translation/tensorflow/transformer_mlperf/training/bfloat16/README.md) |
| Language Translation    | [Transformer_LT_mlperf](https://arxiv.org/pdf/1706.03762.pdf) | Inference | | [FP32](language_translation/tensorflow/transformer_mlperf/inference/fp32/README.md) [BFloat16**](language_translation/tensorflow/transformer_mlperf/inference/bfloat16/README.md) [Int8](language_translation/tensorflow/transformer_mlperf/inference/int8/README.md) |
| Language Translation    | [Transformer_LT_Official](https://arxiv.org/pdf/1706.03762.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-official-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/transformer-lt-official-fp32-inference-tensorflow-model.html)  | [FP32](language_translation/tensorflow/transformer_lt_official/inference/fp32/README.md) |
| Object Detection        | [Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/faster-rcnn-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/faster-rcnn-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/faster-rcnn-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/faster-rcnn-fp32-inference-tensorflow-model.html)  | [Int8](object_detection/tensorflow/faster_rcnn/inference/int8/README.md) [FP32](object_detection/tensorflow/faster_rcnn/inference/fp32/README.md) |
| Object Detection        | [R-FCN](https://arxiv.org/pdf/1605.06409.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-fp32-inference-tensorflow-model.html)  | [Int8](object_detection/tensorflow/rfcn/inference/int8/README.md) [FP32](object_detection/tensorflow/rfcn/inference/fp32/README.md) |
| Object Detection        | [SSD-MobileNet*](https://arxiv.org/pdf/1704.04861.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-mobilenet-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-mobilenet-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-mobilenet-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-mobilenet-fp32-inference-tensorflow-model.html)  | [Int8](object_detection/tensorflow/ssd-mobilenet/inference/int8/README.md) [FP32](object_detection/tensorflow/ssd-mobilenet/inference/fp32/README.md) [BFloat16**](object_detection/tensorflow/ssd-mobilenet/README.md#bfloat16-inference-instructions) |
| Object Detection        | [SSD-ResNet34*](https://arxiv.org/pdf/1512.02325.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-inference-tensorflow-model.html)  | [Int8](object_detection/tensorflow/ssd-resnet34/inference/int8/README.md) [FP32](object_detection/tensorflow/ssd-resnet34/inference/fp32/README.md) [BFloat16**](object_detection/tensorflow/ssd-resnet34/inference/bfloat16/README.md) |
| Object Detection        | [SSD-ResNet34](https://arxiv.org/pdf/1512.02325.pdf) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-training-tensorflow-container.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-bfloat16-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-training-tensorflow-model.html) [BFloat16**](ssd-resnet34-bfloat16-training-tensorflow-model.html) | [FP32](object_detection/tensorflow/ssd-resnet34/training/fp32/README.md) [BFloat16**](object_detection/tensorflow/ssd-resnet34/training/bfloat16/README.md) |
| Recommendation          | [DIEN](https://arxiv.org/abs/1809.03672) | Inference | | [FP32](/benchmarks/recommendation/tensorflow/dien#fp32-inference) [BFloat16**](/benchmarks/recommendation/tensorflow/dien#bfloat16-inference) |
| Recommendation          | [DIEN](https://arxiv.org/abs/1809.03672) | Training | | [FP32](/benchmarks/recommendation/tensorflow/dien#fp32-training) |
| Recommendation          | [NCF](https://arxiv.org/pdf/1708.05031.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ncf-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/ncf-fp32-inference-tensorflow-model.html)  | [FP32](/benchmarks/recommendation/tensorflow/ncf/inference/fp32/README.md) |
| Recommendation          | [Wide & Deep](https://arxiv.org/pdf/1606.07792.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-fp32-inference-tensorflow-model.html)  | [FP32](/benchmarks/recommendation/tensorflow/wide_deep/inference/fp32/README.md) |
| Recommendation          | [Wide & Deep Large Dataset](https://arxiv.org/pdf/1606.07792.pdf) | Inference | Model Containers: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-int8-inference-tensorflow-container.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-fp32-inference-tensorflow-container.html) <br> Model Packages: [Int8](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-int8-inference-tensorflow-model.html) [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-fp32-inference-tensorflow-model.html)  | [Int8](/benchmarks/recommendation/tensorflow/wide_deep_large_ds/inference/int8/README.md) [FP32](/benchmarks/recommendation/tensorflow/wide_deep_large_ds/inference/fp32/README.md) |
| Recommendation          | [Wide & Deep Large Dataset](https://arxiv.org/pdf/1606.07792.pdf) | Training | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-fp32-training-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wide-deep-large-dataset-fp32-training-tensorflow-model.html)  | [FP32](/benchmarks/recommendation/tensorflow/wide_deep_large_ds/training/fp32/README.md) |
| Reinforcement           | [MiniGo](https://arxiv.org/abs/1712.01815.pdf) | Training |  | [FP32](reinforcement/tensorflow/minigo/README.md#fp32-training-instructions) |
| Text-to-Speech          | [WaveNet](https://arxiv.org/pdf/1609.03499.pdf) | Inference | Model Containers: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wavenet-fp32-inference-tensorflow-container.html) <br> Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/wavenet-fp32-inference-tensorflow-model.html)  | [FP32](/benchmarks/text_to_speech/tensorflow/wavenet/inference/fp32/README.md) |

## TensorFlow Serving Use Cases

| Use Case               | Model               | Mode      | Model Documentation |
| -----------------------| ------------------- | --------- |---------------------|
| Image Recognition      | [Inception V3](https://arxiv.org/pdf/1512.00567.pdf)        | Inference | [FP32](image_recognition/tensorflow_serving/inceptionv3/README.md#fp32-inference-instructions) |
| Image Recognition      | [ResNet 50v1.5](https://github.com/tensorflow/models/tree/master/official/resnet) | Inference | [FP32](image_recognition/tensorflow_serving/resnet50v1_5/README.md#fp32-inference-instructions) |
| Language Translation   | [Transformer_LT_Official](https://arxiv.org/pdf/1706.03762.pdf) | Inference | [FP32](language_translation/tensorflow_serving/transformer_lt_official/README.md#fp32-inference-instructions) |
| Object Detection       | [SSD-MobileNet](https://arxiv.org/pdf/1704.04861.pdf)       | Inference | [FP32](object_detection/tensorflow_serving/ssd-mobilenet/README.md#fp32-inference-instructions) |

## PyTorch Use Cases

| Use Case                | Model              | Mode      | oneContainer Portal | Model Documentation |
| ----------------------- | ------------------ | --------- | ------------------- | --------------------|
| Image Recognition       | [ResNet 50](https://arxiv.org/pdf/1512.03385.pdf)   | Inference | Model Packages: [FP32](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-fp32-inference-pytorch-model.html) [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/resnet50-bfloat16-inference-pytorch-model.html)  | [FP32](/quickstart/image_recognition/pytorch/resnet50/inference/cpu/fp32/README.md) [BFloat16**](/quickstart/image_recognition/pytorch/resnet50/inference/cpu/bfloat16/README.md) |
| Recommendation          | [DLRM](https://arxiv.org/pdf/1906.00091.pdf)        | Training  | Model Packages: [BFloat16**](https://software.intel.com/content/www/us/en/develop/articles/containers/dlrm-bfloat16-training-pytorch-model.html) | [BFloat16**](/quickstart/recommendation/pytorch/dlrm/training/cpu/bfloat16/README.md) |

*Means the model belongs to [MLPerf](https://mlperf.org/) models and will be supported long-term.

**Means the BFloat16 data type support is experimental.
