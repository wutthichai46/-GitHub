# Transformer Language

The following documents have instructions for how to run Transformer Language used in mlperf
Benchmark suites for the following modes/platforms:
* [FP32 training](/benchmarks/language_translation/tensorflow/transformer_mlperf/training/fp32/README.md)
* [Bfloat16 training](/benchmarks/language_translation/tensorflow/transformer_mlperf/training/bfloat16/README.md)
* [FP32 inference](/benchmarks/language_translation/tensorflow/transformer_mlperf/inference/fp32/README.md)
* [Bfloat16 inference](/benchmarks/language_translation/tensorflow/transformer_mlperf/inference/bfloat16/README.md)
* [int8 inference](/benchmarks/language_translation/tensorflow/transformer_mlperf/inference/int8/README.md)

Detailed information on Benchmark can be found in [mlperf/training](https://github.com/mlperf/training/tree/master/translation/tensorflow/transformer)
