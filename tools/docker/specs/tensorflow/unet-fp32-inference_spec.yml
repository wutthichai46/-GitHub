releases:
  tf_1.15.2_containers:
    tag_specs:
    - '{_TAG_PREFIX}{intel-tf}{image-segmentation}{unet-fp32-inference}'
slice_sets:
  unet-fp32-inference:
  - add_to_name: -unet-fp32-inference
    args:
    - FETCH_PR=pull/276/head:cpu_optimized
    - TF_UNET_BRANCH=cpu_optimized
    - PACKAGE_NAME=unet-fp32-inference
    - TENSORFLOW_TAG=1.15.2
    dockerfile_subdirectory: model_containers
    documentation:
      - docs:
        - name: Title
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/title.md
        - name: Description
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/description.md
        - name: Download link
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/download.md
        - name: Quick Start Scripts
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/quickstart.md
        - name: Bare Metal
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/baremetal.md
        - name: Docker
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/docker.md
        - name: License
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/license.md
        name: README.md
        text_replace:
          <docker image>: intel/image-segmentation:tf-1.15.2-unet-fp32-inference
          <mode>: inference
          <model name>: UNet
          <package dir>: unet_trained
          <package name>: unet-fp32-inference.tar.gz
          <package url>: https://storage.googleapis.com/intel-optimized-tensorflow/models/v2_5_0/unet-fp32-inference.tar.gz
          <precision>: FP32
          <use case>: image_segmentation
        uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32
      - name: README.md
        text_replace:
          <mode>: inference
          <model name>: UNet
          <precision>: FP32
          <use case>: image_segmentation
          <workload container url>: https://software.intel.com/content/www/us/en/develop/articles/containers/unet-fp32-inference-tensorflow-container.html
        uri: models/benchmarks/image_segmentation/tensorflow/unet/inference/fp32
        docs:
        - name: Title
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/title.md
        - name: Description
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/description.md
        - name: Quick Start Scripts
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/quickstart.md
        - name: AI Kit
          uri: models/quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32/.docs/aikit.md
        - name: Resources
          uri: models/quickstart/common/.docs/resources_with_portal_link.md
      - name: Advanced.md
        text_replace:
          <mode>: inference
          <model name>: UNet
          <precision>: FP32
          <use case>: image_segmentation
          <docker image>: 'intel/intel-optimized-tensorflow:1.15.2'
        uri: models/benchmarks/image_segmentation/tensorflow/unet/inference/fp32
        docs:
        - name: Title
          uri: models/quickstart/common/.docs/advanced/title.md
        - name: Description
          uri: models/quickstart/common/.docs/advanced/description.md
        - name: Setup
          uri: models/quickstart/common/.docs/advanced/setup.md
        - name: Docker arg
          uri: models/quickstart/common/.docs/advanced/docker_arg.md
        - name: Launch benchmark instructions
          uri: models/benchmarks/image_segmentation/tensorflow/unet/inference/fp32/.docs/advanced/launch_benchmark_instructions.md
    downloads:
    - destination: pretrained_model/unet_fp32_pretrained_model.tar.gz
      source: https://storage.googleapis.com/intel-optimized-tensorflow/models/unet_fp32_pretrained_model.tar.gz
    files:
    - destination: benchmarks/common
      source: benchmarks/common
    - destination: benchmarks/image_segmentation/__init__.py
      source: benchmarks/image_segmentation/__init__.py
    - destination: benchmarks/image_segmentation/tensorflow/__init__.py
      source: benchmarks/image_segmentation/tensorflow/__init__.py
    - destination: benchmarks/image_segmentation/tensorflow/unet/README.md
      source: benchmarks/image_segmentation/tensorflow/unet/README.md
    - destination: benchmarks/image_segmentation/tensorflow/unet/__init__.py
      source: benchmarks/image_segmentation/tensorflow/unet/__init__.py
    - destination: benchmarks/image_segmentation/tensorflow/unet/inference/__init__.py
      source: benchmarks/image_segmentation/tensorflow/unet/inference/__init__.py
    - destination: benchmarks/image_segmentation/tensorflow/unet/inference/fp32
      source: benchmarks/image_segmentation/tensorflow/unet/inference/fp32
    - destination: benchmarks/launch_benchmark.py
      source: benchmarks/launch_benchmark.py
    - destination: models/common
      source: models/common
    - destination: quickstart/common
      source: quickstart/common
    - destination: quickstart
      source: quickstart/image_segmentation/tensorflow/unet/inference/cpu/fp32
    partials:
    - image_segmentation/tensorflow-unet
    - image_segmentation/unet_pip_installs
    - model_package
    - entrypoint
    - tar
