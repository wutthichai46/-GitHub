releases:
    versioned:
        tag_specs:
            - "{_TAG_PREFIX}{intel-tf}{object-detection}{rfcn-fp32-inference}"
slice_sets:

    rfcn-fp32-inference:
        - add_to_name: "-rfcn-fp32-inference"
          dockerfile_subdirectory: "model_containers"
          partials:
              - model_package
              - object_detection/rfcn_patch
              - tar
              - entrypoint
          documentation:
            - name: README.md
              uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32
              text_replace:
                <model name>: RFCN
                <precision>: FP32
                <mode>: inference
                <use case>: object_detection
                <package url>: https://storage.googleapis.com/intel-optimized-tensorflow/models/v2_5_0/rfcn-fp32-inference.tar.gz
                <package name>: rfcn-fp32-inference.tar.gz
                <package dir>: rfcn-fp32-inference
                <docker image>: intel/object-detection:tf-latest-rfcn-fp32-inference
                <docker image>: intel/object-detection:tf-latest-rfcn-fp32-inference
              docs:
                  - name: Title
                    uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/title.md
                  - name: Description
                    uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/description.md
                  - name: Download link
                    uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/download.md
                  - name: Datasets
                    uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/datasets.md
                  - name: Quick Start Scripts
                    uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/quickstart.md
                  - name: Bare Metal
                    uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/baremetal.md
                  - name: Docker
                    uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/docker.md
                  - name: License link
                    uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/license.md
            - name: README.md
              uri: models/benchmarks/object_detection/tensorflow/rfcn/inference/fp32
              text_replace:
                <model name>: RFCN
                <precision>: FP32
                <mode>: inference
                <use case>: object_detection
                <workload container url>: https://software.intel.com/content/www/us/en/develop/articles/containers/rfcn-fp32-inference-tensorflow-container.html
              docs:
              - name: Title
                uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/title.md
              - name: Description
                uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/description.md
              - name: Datasets
                uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/datasets.md
              - name: Quick Start Scripts
                uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/quickstart.md
              - name: AI Kit
                uri: models/quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32/.docs/aikit.md
              - name: Resources
                uri: models/quickstart/common/.docs/resources_with_portal_link.md
            - docs:
              - name: Title
                uri: models/quickstart/common/.docs/advanced/title.md
              - name: Description
                uri: models/quickstart/common/.docs/advanced/description.md
              - name: Setup
                uri: models/quickstart/common/.docs/advanced/setup.md
              - name: Docker arg
                uri: models/quickstart/common/.docs/advanced/docker_arg.md
              - name: Launch benchmark instructions
                uri: models/benchmarks/object_detection/tensorflow/rfcn/inference/fp32/.docs/advanced/launch_benchmark_instructions.md
              name: Advanced.md
              text_replace:
                <model name>: RFCN
                <precision>: FP32
                <mode>: inference
                <use case>: object_detection
                <docker image>: 'intel/intel-optimized-tensorflow:latest'
              uri: models/benchmarks/object_detection/tensorflow/rfcn/inference/fp32
          args:
              - TF_MODELS_BRANCH=6c21084503b27a9ab118e1db25f79957d5ef540b
              - PACKAGE_NAME=rfcn-fp32-inference
          files:
              - source: benchmarks/common
                destination: benchmarks/common
              - source: benchmarks/launch_benchmark.py
                destination: benchmarks/launch_benchmark.py
              - source: benchmarks/object_detection/tensorflow/rfcn/inference/fp32
                destination: benchmarks/object_detection/tensorflow/rfcn/inference/fp32
              - source: benchmarks/object_detection/__init__.py
                destination: benchmarks/object_detection/__init__.py
              - source: benchmarks/object_detection/tensorflow/__init__.py
                destination: benchmarks/object_detection/tensorflow/__init__.py
              - source: benchmarks/object_detection/tensorflow/rfcn/__init__.py
                destination: benchmarks/object_detection/tensorflow/rfcn/__init__.py
              - source: benchmarks/object_detection/tensorflow/rfcn/inference/__init__.py
                destination: benchmarks/object_detection/tensorflow/rfcn/inference/__init__.py
              - source: benchmarks/object_detection/tensorflow/rfcn/inference/fp32/__init__.py
                destination: benchmarks/object_detection/tensorflow/rfcn/inference/fp32/__init__.py
              - source: benchmarks/object_detection/tensorflow/rfcn/README.md
                destination: benchmarks/object_detection/tensorflow/rfcn/README.md
              - source: models/object_detection/tensorflow/rfcn/inference/fp32
                destination: models/object_detection/tensorflow/rfcn/inference/fp32
              - source: models/object_detection/tensorflow/rfcn/inference/tf-2.0.patch
                destination: models/object_detection/tensorflow/rfcn/inference/tf-2.0.patch
              - source: quickstart/object_detection/tensorflow/rfcn/inference/cpu/fp32
                destination: quickstart
              - source: quickstart/common
                destination: quickstart/common
          downloads:
              - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/rfcn_resnet101_fp32_coco_pretrained_model.tar.gz
                destination: pretrained_model/rfcn_fp32_model.tar.gz
