releases:
  versioned:
    tag_specs:
    - '{ipex-centos-dlrm-base}{icx-dlrm-fp32}'
slice_sets:
  ipex-centos-dlrm-base:
  - add_to_name: "ipex-centos"
    partials:
      - pytorch/ipex-centos-icx-dlrm-base
    args:
        - IPEX_CONTAINER_TAG=intel/recommendation:pytorch-1.5.0-rc3-icx-a37fb5e8
  icx-dlrm-fp32:
  - add_to_name: -icx-dlrm-fp32
    args:
    - PACKAGE_NAME=icx-dlrm-fp32-inference
    dockerfile_subdirectory: pytorch
    downloads: []
    documentation:
      docs:
      - name: Title
        uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/title.md
      - name: Description
        uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/description.md
      - name: Datasets
        uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/datasets.md
      - name: Quick Start Scripts
        uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/quickstart.md
      - name: Docker
        uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/docker.md
      - name: License
        uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/license.md
      name: README.md
      uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32
    files:
    - destination: quickstart/vanilla_inference_latency.sh
      source: quickstart/ipex-bkc/dlrm-icx/inference/fp32/vanilla_inference_latency.sh
    - destination: quickstart/ipex_inference_latency.sh
      source: quickstart/ipex-bkc/dlrm-icx/inference/fp32/ipex_inference_latency.sh
    - destination: quickstart/inference_accuracy.sh
      source: quickstart/ipex-bkc/dlrm-icx/inference/fp32/inference_accuracy.sh
    - destination: quickstart/dlrm
      source: models/recommendation/pytorch/dlrm/inference
    partials:
    - model_package
    - entrypoint-centos
