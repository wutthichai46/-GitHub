releases:
  versioned:
    tag_specs:
      - '{_TAG_PREFIX}{intel-tf}{object-detection}{rfcn-fp32-inference-k8s}'
slice_sets:
  rfcn-fp32-inference-k8s:
    - add_to_name: -rfcn-fp32-inference-k8s
      documentation:
        - name: README.md
          uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32
          text_replace:
            <model name>: RFCN
            <precision>: FP32
            <mode>: inference
            <use case>: object_detection
            <docker image>: intel/object-detection:tf-latest-rfcn-fp32-inference
            <package url>: https://storage.googleapis.com/intel-optimized-tensorflow/models/v2_5_0/rfcn-fp32-inference-k8s.tar.gz
            <package name>: rfcn-fp32-inference-k8s.tar.gz
            <package dir>: rfcn-fp32-inference-k8s
          docs:
            - name: Title
              uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32/.docs/title.md
            - name: Description
              uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32/.docs/description.md
            - name: Download link
              uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32/.docs/download.md
            - name: Datasets
              uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32/.docs/datasets.md
            - name: Quick Start Scripts
              uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32/.docs/quickstart.md
            - name: Kubernetes
              uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32/.docs/kubernetes.md
            - name: Trouble Shooting
              uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32/.docs/troubleshooting.md
            - name: License link
              uri: models/k8s/object_detection/tensorflow/rfcn/inference/fp32/.docs/license.md
      args:
        - PACKAGE_NAME=rfcn-fp32-inference-k8s
      files:
        - source: k8s/object_detection/tensorflow/rfcn/inference/fp32
          destination: quickstart
        - source: k8s/common
          destination: quickstart/common
      runtime:
        command:
          - kubectl
        args:
          - apply
          - -f
          - user-mounted-nfs.yaml
        env:
          - name: DATASET_DIR
            value: /datasets
          - name: FS_ID
            value: "0"
          - name: GROUP_ID
            value: "0"
          - name: GROUP_NAME
            value: root
          - name: IMAGE_VERSION
            value: tf-latest
          - name: NAME_SPACE
            value: default
          - name: NFS_PATH
            value: /nfs
          - name: NFS_SERVER
            value: 0.0.0.0
          - name: PVC_NAME
            value: workdisk
          - name: PVC_PATH
            value: /pvc
          - name: REGISTRY
            value: docker.io
          - name: USER_ID
            value: "0"
          - name: USER_NAME
            value: root
        tolerations:
          - name: TOLERATION_KEY
            value: dedicated
          - name: TOLERATION_VALUE
            value: CPUPinning
        resources:
          - name: RESOURCE_LIMITS_MEMORY
            value: "5G"
          - name: RESOURCE_LIMITS_CPU
            value: "10"
          - name: RESOURCE_REQUESTS_MEMORY
            value: "5G"
          - name: RESOURCE_REQUESTS_CPU
            value: "10"
        tests:
          - uri: k8s/object_detection/tensorflow/rfcn/inference/fp32/.tests/deployments-yml-exist.sh
          - uri: k8s/object_detection/tensorflow/rfcn/inference/fp32/.tests/namespace-exists.sh
            args:
              - name: USER_NAME
                value: $USER_NAME
          - uri: k8s/object_detection/tensorflow/rfcn/inference/fp32/.tests/serving_deployment.sh
