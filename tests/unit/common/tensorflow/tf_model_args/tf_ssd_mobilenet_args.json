[
  { "_comment": "ssd_mobilenet_fp32_accuracy",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=object_detection --model-name=ssd-mobilenet --precision=fp32 --mode=inference --model-source-dir=/workspace/models --intelai-models=/workspace/intelai_models --num-cores=-1 --batch-size=-1 --socket-id=0 --accuracy-only  --verbose --in-graph=/in_graph/frozen_inference_graph.pb --benchmark-dir=/workspace/benchmarks --data-location=/dataset",
    "output": "numactl --cpunodebind=0 --membind=0 python /workspace/intelai_models/inference/infer_detections.py -g /in_graph/frozen_inference_graph.pb -i 1000 -w 200 -a 28 -e 1 -d /dataset -r",
    "cpuset": "0-111"},

  { "_comment": "ssd_mobilenet_fp32",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=object_detection --model-name=ssd-mobilenet --precision=fp32 --mode=inference --model-source-dir=/workspace/models --benchmark-dir=/workspace/benchmarks --intelai-models=/workspace/intelai_models --num-cores=-1 --batch-size=-1 --socket-id=0  --benchmark-only --verbose --in-graph=/in_graph/frozen_inference_graph.pb  --data-location=/dataset",
    "output": "numactl --cpunodebind=0 --membind=0 python /workspace/intelai_models/inference/infer_detections.py -g /in_graph/frozen_inference_graph.pb -i 1000 -w 200 -a 28 -e 1 -d /dataset -b -1",
    "cpuset": "0-111"},

  { "_comment": "ssd_mobilenet_int8_accuracy",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=object_detection --model-name=ssd-mobilenet --precision=int8 --mode=inference --benchmark-dir=/workspace/benchmarks --intelai-models=/workspace/intelai_models --num-cores=-1 --batch-size=1 --socket-id=0 --output-dir=/workspace/benchmarks/common/tensorflow/logs --accuracy-only --verbose --model-source-dir=/workspace/models --in-graph=/in_graph/ssdmobilenet_int8_pretrained_model.pb --data-location=/dataset",
    "output": "LD_PRELOAD=/usr/lib/libtcmalloc.so.4.2.6 numactl --cpunodebind=0 --membind=0 python /workspace/intelai_models/inference/int8/infer_detections.py -g /in_graph/ssdmobilenet_int8_pretrained_model.pb -i 1000 -w 200 -a 28 -e 1 -d /dataset -r",
    "cpuset": "0-111"},

  { "_comment": "ssd_mobilenet_int8",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=object_detection --model-name=ssd-mobilenet --precision=int8 --mode=inference --model-source-dir=/workspace/models --intelai-models=/workspace/intelai_models --batch-size=1 --socket-id 0 --data-location=/dataset --verbose --in-graph=/in_graph/ssdmobilenet_int8_pretrained_model.pb --benchmark-only --in-graph=/in_graph/ssdmobilenet_int8_pretrained_model.pb",
    "output": "LD_PRELOAD=/usr/lib/libtcmalloc.so.4.2.6 numactl --cpunodebind=0 --membind=0 python /workspace/intelai_models/inference/int8/infer_detections.py -g /in_graph/ssdmobilenet_int8_pretrained_model.pb -i 1000 -w 200 -a 28 -e 1 -d /dataset -b 1",
    "cpuset": "0-111"},

  { "_comment": "ssd_mobilenet_bfloat16_inference",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=object_detection --model-name=ssd-mobilenet --precision=bfloat16 --mode=inference --model-source-dir=/workspace/models --intelai-models=/workspace/intelai_models --socket-id=0 --data-location=/dataset/coco_val.record --benchmark-only --in-graph=/in_graph/ssdmobilenet_fp32_pretrained_model_combinedNMS.pb",
    "output": "numactl --cpunodebind=0 --membind=0 python /workspace/intelai_models/inference/infer_detections.py -g /in_graph/ssdmobilenet_fp32_pretrained_model_combinedNMS.pb -i 1000 -w 200 -a 28 -e 1 -p bfloat16 -d /dataset/coco_val.record -b -1",
    "cpuset": "0-111"},

  { "_comment": "ssd_mobilenet_bfloat16_accuracy",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=object_detection --model-name=ssd-mobilenet --precision=bfloat16 --mode=inference --model-source-dir=/workspace/models --intelai-models=/workspace/intelai_models --socket-id=0 --data-location=/dataset/coco_val.record --accuracy-only --in-graph=/in_graph/ssdmobilenet_fp32_pretrained_model_combinedNMS.pb",
    "output": "numactl --cpunodebind=0 --membind=0 python /workspace/intelai_models/inference/infer_detections.py -g /in_graph/ssdmobilenet_fp32_pretrained_model_combinedNMS.pb -i 1000 -w 200 -a 28 -e 1 -p bfloat16 -d /dataset/coco_val.record -r",
    "cpuset": "0-111"},

  { "_comment": "ssd_mobilenet_bfloat16_inference",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=object_detection --model-name=ssd-mobilenet --precision=bfloat16 --mode=inference --model-source-dir=/workspace/models --intelai-models=/workspace/intelai_models --data-location=/dataset/coco_val.record --benchmark-only --in-graph=/in_graph/ssdmobilenet_fp32_pretrained_model_combinedNMS.pb",
    "output": "python /workspace/intelai_models/inference/infer_detections.py -g /in_graph/ssdmobilenet_fp32_pretrained_model_combinedNMS.pb -i 1000 -w 200 -a 16 -e 1 -p bfloat16 -d /dataset/coco_val.record -b -1",
    "cpuset": "0-7,8-15"},

  { "_comment": "ssd_mobilenet_fp32_cpuset",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=object_detection --model-name=ssd-mobilenet --precision=fp32 --mode=inference --model-source-dir=/workspace/models --benchmark-dir=/workspace/benchmarks --intelai-models=/workspace/intelai_models --batch-size=-1 --benchmark-only --verbose --in-graph=/in_graph/frozen_inference_graph.pb  --data-location=/dataset",
    "output": "python /workspace/intelai_models/inference/infer_detections.py -g /in_graph/frozen_inference_graph.pb -i 1000 -w 200 -a 8 -e 2 -d /dataset -b -1",
    "cpuset": "25-28,0-3"}
]
