[
  { "_comment": "FP32 latency benchmark",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=language_translation --model-name=gnmt --precision=fp32 --mode=inference --model-source-dir=/workspace/models --benchmark-dir=/workspace/benchmarks --intelai-models=/workspace/intelai_models --num-cores=-1 --batch-size=1 --socket-id=0 --output-dir=/workspace/benchmarks/common/tensorflow/logs --benchmark-only --verbose --checkpoint=/checkpoints --data-location=/dataset --infer_mode=beam_search",
    "output": "numactl --cpunodebind=0 --membind=0 python /workspace/intelai_models/inference/fp32/nmt.py --src=de --tgt=en --hparams_path=/workspace/intelai_models/inference/fp32/standard_hparams/wmt16_gnmt_4_layer_internal.json --out_dir=/workspace/benchmarks/common/tensorflow/logs --vocab_prefix=/dataset/vocab.bpe.32000 --ckpt=/checkpoints/translate.ckpt --infer_batch_size=1 --inference_input_file=/dataset/newstest2015.tok.bpe.32000.de --inference_output_file=/workspace/benchmarks/common/tensorflow/logs/output_infer --inference_ref_file=/dataset/newstest2015.tok.bpe.32000.en --num_inter_threads=1 --num_intra_threads=28 --infer_mode=beam_search"},

  { "_comment": "FP32 Throughput benchmark",
    "input": "run_tf_benchmark.py --framework=tensorflow --use-case=language_translation --model-name=gnmt --precision=fp32 --mode=inference --model-source-dir=/workspace/models --benchmark-dir=/workspace/benchmarks --intelai-models=/workspace/intelai_models --num-cores=-1 --batch-size=32 --socket-id=0 --output-dir=/workspace/benchmarks/common/tensorflow/logs --benchmark-only --verbose --checkpoint=/checkpoints --data-location=/dataset --infer_mode=beam_search",
    "output": "numactl --cpunodebind=0 --membind=0 python /workspace/intelai_models/inference/fp32/nmt.py --src=de --tgt=en --hparams_path=/workspace/intelai_models/inference/fp32/standard_hparams/wmt16_gnmt_4_layer_internal.json --out_dir=/workspace/benchmarks/common/tensorflow/logs --vocab_prefix=/dataset/vocab.bpe.32000 --ckpt=/checkpoints/translate.ckpt --infer_batch_size=32 --inference_input_file=/dataset/newstest2015.tok.bpe.32000.de --inference_output_file=/workspace/benchmarks/common/tensorflow/logs/output_infer --inference_ref_file=/dataset/newstest2015.tok.bpe.32000.en --num_inter_threads=1 --num_intra_threads=28 --infer_mode=beam_search"},

 { "_comment": "FP32 Training",
    "input": "python common/tensorflow/run_tf_benchmark.py --framework=tensorflow --use-case=language_translation --model-name=gnmt --precision=fp32 --mode=training --benchmark-dir=/workspace/benchmarks --intelai-models=/workspace/intelai_models --num-cores=-1 --batch-size=512 --socket-id=0 --output-dir=/workspace/benchmarks/common/tensorflow/logs --num-processes=2 --num-processes-per-node=1 --num-train-steps=300 --benchmark-only --model-source-dir=/workspace/models --data-location=/dataset --num-inter-threads=1 --num-intra-threads=28 --disable-tcmalloc=True --src=de --tgt=en --vocab_prefix=vocab.bpe.32000 --train_prefix=train.tok.clean.bpe.32000 --dev_prefix=newstest2013.tok.bpe.32000 --test_prefix=newstest2015.tok.bpe.32000 --num_units=1024 --dropout=0.2 --hparams_path=nmt/standard_hparams/wmt16_gnmt_4_layer_multi_instances.json",
    "output": "mpirun -n 2 -ppn 1 -genv I_MPI_ASYNC_PROGRESS=1 -genv I_MPI_FABRICS=shm -genv I_MPI_PIN_DOMAIN=socket -genv I_MPI_ASYNC_PROGRESS_PIN=0,28 -genv OMP_NUM_THREADS=28 python -m  nmt.nmt  --src=de --tgt=en --vocab_prefix=/dataset/vocab.bpe.32000 --train_prefix=/dataset/train.tok.clean.bpe.32000 --dev_prefix=/dataset/newstest2013.tok.bpe.32000 --test_prefix=/dataset/newstest2015.tok.bpe.32000 --out_dir=/workspace/benchmarks/common/tensorflow/logs --num_units=1024 --dropout=0.2 --batch_size=512 --num_inter_threads=1 --num_intra_threads=28 --num_train_steps=300 --hparams_path=nmt/standard_hparams/wmt16_gnmt_4_layer_multi_instances.json"}
]


